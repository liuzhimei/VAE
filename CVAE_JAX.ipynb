{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa36f9d-ccc8-42e6-bd96-f67eec9047f0",
   "metadata": {},
   "source": [
    "# Conditional Variational Autoencoder with JAX \n",
    "Trained with MNIST images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e488b-e180-4427-92ac-503b532003e2",
   "metadata": {},
   "source": [
    "## How the CVAE learns the connection between images and labels:\n",
    "1. Conditional Encoding and Latent Space Structuring\n",
    "\n",
    "    In the encoder, both the image $x$ and label $c$ (converted to a one-hot encoded vector) are concatenated and passed through the network to learn a latent representation $z$. By including $c$, the encoder learns to structure the latent space based on this additional label information, enabling it to differentiate representations by class or label.\n",
    "\n",
    "    The encoder learns to map $(x,c)$ to a latent distribution $q(z|x,c)$, capturing data variations within each class separately.\n",
    "\n",
    "    This structuring means that, for example, latent representations for images of a digit \"3\" will be more clustered in one part of the space, while \"7\" might be in another, with the label $c$ guiding this separation.\n",
    "\n",
    "2. Conditional Decoding\n",
    "\n",
    "   During decoding, the CVAE uses both the latent variable $z$ and the label $c$ to reconstruct the input as $p(x|z,c)$. This conditioning ensures that generated samples are aligned with the given label $c$, allowing the model to output images that resemble the conditioned label. Essentially, it gives control over the generation process, making it possible to generate specific types of data (e.g., MNIST digits corresponding to \"3\" or \"7\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288905e1-1e61-49d8-88b6-dace5a88a204",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9687808-279b-4e25-87e2-39aa28f62906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aed8e9-a761-4d3f-a51c-1e9f12539570",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1cdb9-1497-402e-bb98-c5ecbd346534",
   "metadata": {},
   "source": [
    "## Onehot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f774e1d-bb9c-4764-9ab5-b3f2dae2b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x, max_dim):\n",
    "    \"\"\"Convert labels to one-hot encoding.\"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    vector = jnp.zeros((batch_size, max_dim))\n",
    "    one_hot = vector.at[jnp.arange(batch_size), x].set(1)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf5514-67bc-4e2e-b0d6-d12db4ca588a",
   "metadata": {},
   "source": [
    "## Build encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5c0603d-b3ce-4dde-a96f-7431ca928f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    hidden_size: int\n",
    "    latent_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.linear = nn.Dense(self.hidden_size)\n",
    "        self.mu = nn.Dense(self.latent_size)\n",
    "        self.sigma = nn.Dense(self.latent_size)\n",
    "        \n",
    "        # # Convolutional layers\n",
    "        # self.conv1 = nn.Conv(features=32, kernel_size=(3, 3), strides=(2, 2))  # output: 14x14x32\n",
    "        # self.conv2 = nn.Conv(features=64, kernel_size=(3, 3), strides=(2, 2))  # output: 7x7x64\n",
    "\n",
    "        # # Fully connected layers\n",
    "        # self.fc = nn.Dense(self.hidden_size)\n",
    "        # self.mu = nn.Dense(self.latent_size)\n",
    "        # self.sigma = nn.Dense(self.latent_size)\n",
    "\n",
    "    # def __call__(self, x):\n",
    "    #     x = nn.relu(self.conv1(x))\n",
    "    #     x = nn.relu(self.conv2(x))\n",
    "    #     x = jnp.reshape(x, (x.shape[0], -1))  # Flatten the 2D feature maps manually\n",
    "    #     x = nn.relu(self.fc(x))\n",
    "    #     mu = self.mu(x)\n",
    "    #     sigma = self.sigma(x)\n",
    "    #     return mu, sigma\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # print(\"Input to Encoder:\", x.shape)  # Print input shape\n",
    "        x = nn.relu(self.linear(x))\n",
    "        # print(\"After Linear Layer:\", x.shape)  # Print shape after linear layer\n",
    "        mu = self.mu(x)\n",
    "        # print(\"Mu Shape:\", mu.shape)  # Print mu shape\n",
    "        sigma = self.sigma(x)\n",
    "        # print(\"Sigma Shape:\", sigma.shape)  # Print sigma shape\n",
    "        return mu, sigma\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05919c-18d8-440c-a297-89e5a0547267",
   "metadata": {},
   "source": [
    "## Build decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b473f264-9d85-4215-bb37-25337537b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    hidden_size: int\n",
    "    output_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.linear1 = nn.Dense(self.hidden_size)\n",
    "        self.linear2 = nn.Dense(self.output_size)\n",
    "\n",
    "        # # Fully connected layers to expand from latent space to feature map\n",
    "        # self.fc = nn.Dense(self.hidden_size)\n",
    "        # self.fc_reshape = nn.Dense(7 * 7 * 64)\n",
    "        \n",
    "        # # Transpose Convolutional layers\n",
    "        # self.fc_reshape = nn.Dense(7 * 7 * 64)\n",
    "        # self.convT1 = nn.ConvTranspose(features=64, kernel_size=(3, 3), strides=(2, 2), padding='SAME')  # upsample to 14x14\n",
    "        # self.convT2 = nn.ConvTranspose(features=32, kernel_size=(3, 3), strides=(2, 2), padding='SAME')  # upsample to 28x28\n",
    "        # self.convT3 = nn.ConvTranspose(features=1, kernel_size=(3, 3), strides=(1, 1), padding='SAME')  # final output\n",
    "\n",
    "\n",
    "    # def __call__(self, x):\n",
    "        # x = nn.relu(self.fc(x))\n",
    "        # x = nn.relu(self.fc_reshape(x))\n",
    "        # x = jnp.reshape(x, (-1, 7, 7, 64))  # Reshape to a 2D feature map for transposed convolutions\n",
    "        # x = nn.relu(self.convT1(x))\n",
    "        # x = nn.relu(self.convT2(x))\n",
    "        # x = nn.sigmoid(self.convT3(x)).reshape((-1, 28 * 28))  # Flatten for binary cross-entropy\n",
    "        # return x\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # print(\"Input to Decoder:\", x.shape)  # Print input shape\n",
    "        x = nn.relu(self.linear1(x))\n",
    "        # print(\"After First Linear Layer:\", x.shape)  # Print shape after first linear layer\n",
    "        x = nn.sigmoid(self.linear2(x))\n",
    "        # print(\"Output Shape:\", x.shape)  # Print output shape\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b072bd8-f37b-4975-8f37-c7aa95e17faa",
   "metadata": {},
   "source": [
    "## Combine encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea5465f2-11a5-4d4f-b633-b0c4d5a1ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    condition_size: int\n",
    "    latent_size: int\n",
    "    hidden_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(hidden_size=self.hidden_size, latent_size=self.latent_size)\n",
    "        self.decoder = Decoder(hidden_size=self.hidden_size, output_size=self.output_size)\n",
    "\n",
    "    def __call__(self, x, c):\n",
    "        # print(\"Shape of x:\", x.shape)\n",
    "        # print(\"Shape of c:\", c.shape)\n",
    "        x = jnp.concatenate((x, c), axis=1) # Concatenate the input x and condition c\n",
    "        # print(\"Shape after concatenating x and c:\", x.shape)  # Print input shape to CVAE\n",
    "        mu, sigma = self.encoder(x)\n",
    "        # print(\"Mu Shape:\", mu.shape)  # Print shape of mu\n",
    "        # print(\"Sigma Shape:\", sigma.shape)  # Print shape of sigma\n",
    "\n",
    "        # Sample from standard normal distribution\n",
    "        eps = jax.random.normal(jax.random.PRNGKey(0), sigma.shape)\n",
    "        z = mu + eps * jnp.exp(0.5 * sigma)\n",
    "        z_cond = jnp.concatenate((z, c), axis=1)\n",
    "        # print(\"Input to Decoder:\", z.shape)  # Print input shape to decoder\n",
    "\n",
    "        recon_x = self.decoder(z_cond)\n",
    "        return recon_x, mu, sigma\n",
    "\n",
    "    def decode(self, z, c):\n",
    "        \"\"\"Decode from latent space given a condition.\"\"\"\n",
    "        z = jnp.concatenate((z, c), axis=1)  # Concatenate latent vector and condition\n",
    "        return self.decoder(z)  # Use decoder to reconstruct the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ccb0c-3171-4e68-9b93-bd1a1298b76a",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0258ce1-1bad-4379-a9df-e941753770c1",
   "metadata": {},
   "source": [
    "The CVAEâ€™s loss function has the same terms as the VAE, combining the **reconstruction loss** (likelihood of data given latent and condition) and the **KL divergence** (difference between learned and prior distributions). However, both terms now incorporate the condition $c$ as a context, which refines how the loss shapes the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f2f997b-fbd1-407c-8c75-7502bae63b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, sigma):\n",
    "    \"\"\"Compute the loss for the CVAE.\"\"\"\n",
    "    loss_re = optax.sigmoid_binary_cross_entropy(recon_x, x).sum()\n",
    "    loss_norm = -0.5 * jnp.sum(1 + sigma - jnp.square(mu) - jnp.exp(sigma))\n",
    "    return loss_re + loss_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3569cd-4259-4ce6-b673-dd913c943a92",
   "metadata": {},
   "source": [
    "# Hyperparameters and model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9d3a9-9bf7-4767-8afc-7c9e3e762444",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a7ced0f-4b18-49a7-92ca-ccf0430ff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 16  # latent space dimension\n",
    "hidden_size = 128  # hidden layer dimension\n",
    "input_size = output_size = 28 * 28 \n",
    "condition_size = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5e076-7991-417a-a649-ab58430ede4a",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be3b4bd8-e703-4769-a9b6-fef26ca49182",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32 \n",
    "learning_rate = 3e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2b969-03dd-4cfb-ba01-893613034f26",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44e48382-5dd6-466d-bd35-fbcd531d4fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "model = CVAE(input_size, output_size, condition_size, latent_size, hidden_size)\n",
    "# Update the input shape to include the condition size\n",
    "input_shape = (batch_size, input_size)  # Correct shape\n",
    "params = model.init(jax.random.PRNGKey(0), jnp.ones(input_shape), jnp.ones((batch_size, condition_size)))\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628d2d4-f9c1-4ec2-a7bc-4c862a340545",
   "metadata": {},
   "source": [
    "# Load dataset and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe1a4141-7589-4a85-a0c7-4844dbcd795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using PyTorch\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05e6c558-ccc6-4ed4-b501-466796417167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zx/j5d_p2_s2wz05zg3b78717100000gn/T/ipykernel_39193/679139505.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_tensor = torch.tensor(batch[0])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    # Convert the list to a tensor\n",
    "    data_tensor = torch.tensor(batch[0])\n",
    "    print(data_tensor.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "164e7764-1e04-4a59-a5e2-a9c75978544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 60000\n",
      "Number of samples in test dataset: 10000\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the dataset\n",
    "print(f\"Number of samples in training set: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in test dataset: {len(test_dataset)}\")\n",
    "print(train_dataset[60][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc488584-70f7-49fe-b679-19687877e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n",
      "Image data type: torch.float32\n",
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inspect_train_set(train_dataset):\n",
    "    '''Function to inspect the train_set'''\n",
    "\n",
    "    # Get the first sample (image, label)\n",
    "    sample_image, sample_label = train_dataset[60]\n",
    "\n",
    "    # Check the shape and type of the image\n",
    "    print(f\"Image shape: {sample_image.shape}\")\n",
    "    print(f\"Image data type: {sample_image.dtype}\")\n",
    "    print(f\"Label: {sample_label}\")\n",
    "\n",
    "    # Visualize the first image\n",
    "    plt.imshow(sample_image.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Label: {sample_label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Inspect the train_set\n",
    "inspect_train_set(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05b4762f-b6b4-4280-b7f7-c53d781ad5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for imgs, lbls in tqdm(train_loader):\n",
    "#     # Flatten images to shape (batch_size, 784)\n",
    "#     imgs = imgs.view(imgs.shape[0], -1)  \n",
    "#     print(\"Shape of imgs:\", imgs.shape)  # Should be (batch_size, 784)\n",
    "    \n",
    "#     # One-hot encode the labels\n",
    "#     lbls = onehot(lbls.numpy(), condition_size)  # Convert to one-hot encoding\n",
    "#     print(\"Shape of lbls:\", lbls.shape)  # Should be (batch_size, 10)\n",
    "\n",
    "#     # Convert to JAX arrays\n",
    "#     imgs = jnp.array(imgs.numpy())  # Shape (batch_size, 784)\n",
    "#     lbls = jnp.array(lbls)  # Shape (batch_size, 10)\n",
    "\n",
    "#     # Concatenate images and labels for encoder input\n",
    "#     inputs = jnp.concatenate((imgs, lbls), axis=1)  # Shape (batch_size, 794)\n",
    "#     print(\"Shape of inputs:\", inputs.shape)  # Should be (batch_size, 794)\n",
    "    \n",
    "#     params = model.init(jax.random.PRNGKey(0), inputs, lbls)  # Initialize parameters\n",
    "\n",
    "#     # Call the model with both inputs\n",
    "#     recon_x, mu, sigma = model.apply(params, inputs, lbls)  # Pass lbls as the second argument\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c57b1-d2b0-4da7-9520-c621d24ab7c6",
   "metadata": {},
   "source": [
    "# Train the model and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbdd2eec-7e86-45bd-a7e7-62b600bf7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:13<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0| Train Loss:  17351.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 75.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0| Test Loss:  17203.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:14<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1| Train Loss:  17205.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 77.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1| Test Loss:  17132.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:12<00:00, 25.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2| Train Loss:  17157.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 77.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2| Test Loss:  17099.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:13<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3| Train Loss:  17131.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 76.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3| Test Loss:  17075.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:12<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4| Train Loss:  17113.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 68.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4| Test Loss:  17066.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:11<00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5| Train Loss:  17098.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 76.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5| Test Loss:  17044.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:12<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6| Train Loss:  17084.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 77.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6| Test Loss:  17032.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:11<00:00, 26.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7| Train Loss:  17071.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 72.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7| Test Loss:  17021.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:12<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8| Train Loss:  17061.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 75.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8| Test Loss:  17004.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [01:13<00:00, 25.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9| Train Loss:  17046.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:04<00:00, 76.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9| Test Loss:  16998.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    for imgs, lbls in tqdm(train_loader):\n",
    "        imgs = imgs.view(imgs.shape[0], input_size)  # Flatten the images\n",
    "\n",
    "        # print(f\"input of onehot function: {lbls.numpy()}\")\n",
    "        lbls = onehot(lbls.numpy(), condition_size)  # Convert labels to one-hot encoding\n",
    "        # print(f\"output of onehot function: {lbls}\")\n",
    "\n",
    "        # Move data to JAX compatible format\n",
    "        imgs = jnp.array(imgs.numpy())  # Convert to JAX array\n",
    "        lbls = jnp.array(lbls)  # Convert to JAX array\n",
    "\n",
    "        def loss_fn_wrapper(params):\n",
    "            recon_x, mu, sigma = model.apply(params, imgs, lbls)\n",
    "            return loss_fn(recon_x, imgs, mu, sigma)\n",
    "\n",
    "        loss, grads = jax.value_and_grad(loss_fn_wrapper)(params)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "    print(f'epoch: {epoch}| Train Loss: ', train_loss / len(train_loader))\n",
    "\n",
    "    # Evaluation\n",
    "    test_loss = 0\n",
    "    for imgs, lbls in tqdm(test_loader):\n",
    "        imgs = imgs.view(imgs.shape[0], input_size)\n",
    "        lbls = onehot(lbls.numpy(), condition_size)\n",
    "        \n",
    "        imgs = jnp.array(imgs.numpy())\n",
    "        lbls = jnp.array(lbls)\n",
    "\n",
    "        recon_x, mu, sigma = model.apply(params, imgs, lbls)\n",
    "        loss = loss_fn(recon_x, imgs, mu, sigma)\n",
    "        test_loss += loss\n",
    "\n",
    "    print(f'epoch: {epoch}| Test Loss: ', test_loss / len(test_loader))\n",
    "\n",
    "    \n",
    "    # # Sample and visualize generated data\n",
    "    # sample = jax.random.normal(jax.random.PRNGKey(1), (1, latent_size))\n",
    "\n",
    "    # for i in range(condition_size):\n",
    "    #     i_number = i * jnp.ones((1,), dtype=int)\n",
    "    #     cond = onehot(i_number, condition_size)\n",
    "    #     inputs = jnp.concatenate((sample, cond), axis=1)\n",
    "\n",
    "    #     # params = model.init(jax.random.PRNGKey(0), inputs, lbls)  # Initialize parameters\n",
    "        \n",
    "    #     # Use model.apply to call the decoder\n",
    "    #     gen = model.apply(params, inputs, cond)[0].reshape((28, 28))\n",
    "    #     plt.matshow(gen)\n",
    "    #     plt.show()\n",
    "\n",
    "# Save the final model parameters after all epochs are completed\n",
    "model_name = \"cvae_jax.pkl\"\n",
    "with open(model_name, \"wb\") as f:\n",
    "    pickle.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "de85ca09-1713-4d28-aa65-ee8303536d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the saved model parameters\n",
    "model_name = \"cvae_jax.pkl\"\n",
    "with open(model_name, \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "\n",
    "# Generate a random sample from the latent space\n",
    "key = jax.random.PRNGKey(0) # change the random key to generate different image\n",
    "sample = jax.random.normal(key, (1, latent_size))  # Shape (1, latent_size)\n",
    "\n",
    "# Define the label to condition on\n",
    "i = 8\n",
    "i_array = jnp.array([i])  # Wrap `i` in an array\n",
    "i_onehot = onehot(i_array, condition_size)  # Use the `onehot` function\n",
    "\n",
    "# Generate the output with the decode method\n",
    "gen_image = model.apply(params, sample, i_onehot, method=model.decode).reshape(28, 28)\n",
    "\n",
    "# Visualize the generated image\n",
    "plt.imshow(gen_image, cmap='gray', interpolation='bilinear')\n",
    "plt.gcf().set_size_inches(2, 2)  # Adjust display size\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b649835-c197-4f6c-9b4e-ff21361ea7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vae_env)",
   "language": "python",
   "name": "vae_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
